# BigQueryä¸“æœ‰è¡¨è®¾è®¡ä¸æ•°æ®å¯¼å…¥æ–¹æ¡ˆ

## 1. åˆ›å»ºä¸“æœ‰è¡¨

```sql
-- åœ¨BigQueryæ§åˆ¶å°æ‰§è¡Œ
-- æˆ–é€šè¿‡ bq å‘½ä»¤è¡Œå·¥å…·

CREATE TABLE `windy10v10ai.dota2.matches` (
  -- æ ¸å¿ƒå­—æ®µ
  match_id STRING NOT NULL,
  timestamp TIMESTAMP NOT NULL,

  -- å¯¹å±€ç»“æœ
  winner INT64 NOT NULL,  -- 2=Radiant, 3=Dire

  -- è‹±é›„é˜µå®¹ï¼ˆMLè®­ç»ƒæ ¸å¿ƒç‰¹å¾ï¼‰
  radiant_heroes ARRAY<INT64> NOT NULL,  -- é•¿åº¦1-10ï¼Œå¯é‡å¤
  dire_heroes ARRAY<INT64> NOT NULL,     -- é•¿åº¦å›ºå®š10ï¼Œä¸é‡å¤

  -- å¯¹å±€å…ƒæ•°æ®
  duration_msec INT64,
  game_version STRING,
  difficulty INT64,
  server_type STRING,

  -- AIæ¨èç›¸å…³ï¼ˆç”¨äºABæµ‹è¯•å’Œæ•ˆæœè¯„ä¼°ï¼‰
  recommendation_strategy STRING,  -- 'baseline', 'xgboost_v1', 'xgboost_v2', 'random' ç­‰

  -- ç»Ÿè®¡å­—æ®µ
  radiant_player_count INT64,
  dire_player_count INT64
)
PARTITION BY DATE(timestamp)
CLUSTER BY winner, difficulty
OPTIONS(
  description = "Dota2 10v10 match records for AI hero recommendation",
  require_partition_filter = false
);
```

**è®¾è®¡è¦ç‚¹**ï¼š
- âœ… **åˆ†åŒº**ï¼šæŒ‰æ—¥æœŸåˆ†åŒºï¼Œæé«˜æŸ¥è¯¢æ•ˆç‡
- âœ… **èšç°‡**ï¼šæŒ‰winnerå’Œdifficultyèšç°‡ï¼ŒåŠ é€Ÿè®­ç»ƒæ•°æ®ç­›é€‰
- âœ… **NOT NULLçº¦æŸ**ï¼šç¡®ä¿æ ¸å¿ƒå­—æ®µå®Œæ•´æ€§
- âœ… **æ•°ç»„ç±»å‹**ï¼šç›´æ¥å­˜å‚¨è‹±é›„IDæ•°ç»„ï¼Œæ— éœ€JOIN

---

## 2. ä»GA4å¯¼å…¥å†å²æ•°æ®

### æ–¹å¼Aï¼šä¸€æ¬¡æ€§å¯¼å…¥ï¼ˆæ¨èï¼‰

åˆ›å»ºSQLæ–‡ä»¶ `ml/data/import_ga4_to_dedicated_table.sql`ï¼š

```sql
-- ml/data/import_ga4_to_dedicated_table.sql
-- ä»GA4äº‹ä»¶è¡¨å¯¼å…¥å†å²å¯¹å±€æ•°æ®åˆ°ä¸“æœ‰è¡¨

INSERT INTO `windy10v10ai.dota2.matches`
(
  match_id,
  timestamp,
  winner,
  radiant_heroes,
  dire_heroes,
  duration_msec,
  game_version,
  difficulty,
  server_type,
  recommendation_strategy,
  radiant_player_count,
  dire_player_count
)

WITH parsed_matches AS (
  SELECT
    event_timestamp,
    (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'match_id') as match_id,
    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'winner_team_id') as winner,
    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'difficulty') as difficulty,
    (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'version') as version,
    (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'server_type') as server_type,
    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'engagement_time_msec') as duration_msec,
    -- æå–æ‰€æœ‰ç©å®¶æ•°æ®ï¼ˆplayer_1åˆ°player_20ï¼‰
    ARRAY_CONCAT(
      ARRAY[
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_1'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_2'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_3'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_4'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_5'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_6'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_7'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_8'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_9'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_10')
      ],
      ARRAY[
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_11'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_12'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_13'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_14'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_15'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_16'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_17'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_18'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_19'),
        (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'player_20')
      ]
    ) as players_json
  FROM `windy10v10ai.analytics_<PROPERTY_ID>.events_*`
  WHERE event_name = 'game_end_match'
    -- å¯¼å…¥æœ€è¿‘6ä¸ªæœˆçš„æ•°æ®ï¼ˆå¯è°ƒæ•´ï¼‰
    AND _TABLE_SUFFIX BETWEEN FORMAT_DATE('%Y%m%d', DATE_SUB(CURRENT_DATE(), INTERVAL 180 DAY))
                          AND FORMAT_DATE('%Y%m%d', CURRENT_DATE())
),

extracted_heroes AS (
  SELECT
    match_id,
    TIMESTAMP_MICROS(event_timestamp) as timestamp,
    winner,
    difficulty,
    version as game_version,
    server_type,
    duration_msec,
    -- æå–Radiantè‹±é›„
    ARRAY(
      SELECT CAST(JSON_EXTRACT_SCALAR(player_json, '$.hi') AS INT64)
      FROM UNNEST(players_json) as player_json
      WHERE player_json IS NOT NULL
        AND JSON_EXTRACT_SCALAR(player_json, '$.ti') = '2'  -- teamId = 2 (Radiant)
        AND JSON_EXTRACT_SCALAR(player_json, '$.hi') IS NOT NULL
    ) as radiant_heroes,
    -- æå–Direè‹±é›„
    ARRAY(
      SELECT CAST(JSON_EXTRACT_SCALAR(player_json, '$.hi') AS INT64)
      FROM UNNEST(players_json) as player_json
      WHERE player_json IS NOT NULL
        AND JSON_EXTRACT_SCALAR(player_json, '$.ti') = '3'  -- teamId = 3 (Dire)
        AND JSON_EXTRACT_SCALAR(player_json, '$.hi') IS NOT NULL
    ) as dire_heroes
  FROM parsed_matches
  WHERE match_id IS NOT NULL
)

SELECT
  match_id,
  timestamp,
  winner,
  radiant_heroes,
  dire_heroes,
  duration_msec,
  game_version,
  difficulty,
  server_type,
  NULL as recommendation_strategy,  -- å†å²æ•°æ®æ— æ­¤å­—æ®µï¼Œè®¾ä¸ºNULL
  ARRAY_LENGTH(radiant_heroes) as radiant_player_count,
  ARRAY_LENGTH(dire_heroes) as dire_player_count
FROM extracted_heroes
WHERE
  -- æ•°æ®è´¨é‡è¿‡æ»¤
  winner IN (2, 3)
  AND ARRAY_LENGTH(radiant_heroes) >= 1
  AND ARRAY_LENGTH(radiant_heroes) <= 10
  AND ARRAY_LENGTH(dire_heroes) = 10
  -- å»é‡ï¼ˆå¦‚æœæœ‰é‡å¤çš„match_idï¼‰
  AND match_id NOT IN (
    SELECT match_id FROM `windy10v10ai.dota2.matches`
  )
ORDER BY timestamp DESC;
```

**æ‰§è¡Œæ­¥éª¤**ï¼š

```bash
# 1. æ›¿æ¢ <PROPERTY_ID> ä¸ºå®é™…çš„GA4 Property ID
sed 's/<PROPERTY_ID>/YOUR_PROPERTY_ID/g' ml/data/import_ga4_to_dedicated_table.sql > ml/data/import_temp.sql

# 2. æ‰§è¡Œå¯¼å…¥ï¼ˆé€šè¿‡bqå‘½ä»¤è¡Œï¼‰
bq query --use_legacy_sql=false < ml/data/import_temp.sql

# æˆ–åœ¨BigQueryæ§åˆ¶å°ç›´æ¥ç²˜è´´æ‰§è¡Œ
```

### æ–¹å¼Bï¼šPythonè„šæœ¬å¯¼å…¥ï¼ˆæ›´çµæ´»ï¼‰

åˆ›å»º `ml/data/import_ga4_data.py`ï¼š

```python
# ml/data/import_ga4_data.py
"""
ä»GA4äº‹ä»¶è¡¨å¯¼å…¥å†å²æ•°æ®åˆ°ä¸“æœ‰è¡¨
"""
from google.cloud import bigquery
import argparse
from datetime import datetime

def import_ga4_data(property_id: str, days: int = 180, dry_run: bool = False):
    """
    ä»GA4å¯¼å…¥å†å²æ•°æ®

    Args:
        property_id: GA4 Property ID
        days: å¯¼å…¥æœ€è¿‘Nå¤©çš„æ•°æ®
        dry_run: åªç»Ÿè®¡æ•°æ®é‡ï¼Œä¸å®é™…å¯¼å…¥
    """
    client = bigquery.Client()

    # è¯»å–SQLæ¨¡æ¿
    with open('import_ga4_to_dedicated_table.sql', 'r') as f:
        query = f.read()

    # æ›¿æ¢å‚æ•°
    query = query.replace('<PROPERTY_ID>', property_id)
    query = query.replace('INTERVAL 180 DAY', f'INTERVAL {days} DAY')

    if dry_run:
        # åªç»Ÿè®¡æ•°æ®é‡
        count_query = f"""
        SELECT COUNT(*) as total
        FROM ({query.replace('INSERT INTO', 'SELECT * FROM')})
        """
        result = client.query(count_query).result()
        total = list(result)[0]['total']
        print(f"ğŸ“Š å°†å¯¼å…¥ {total:,} åœºå¯¹å±€æ•°æ®")
        return total

    # æ‰§è¡Œå¯¼å…¥
    print(f"ğŸš€ å¼€å§‹å¯¼å…¥æ•°æ®...")
    job = client.query(query)
    result = job.result()

    print(f"âœ… å¯¼å…¥å®Œæˆï¼")
    print(f"   - æ’å…¥è¡Œæ•°: {job.num_dml_affected_rows:,}")
    print(f"   - å¤„ç†å­—èŠ‚: {job.total_bytes_processed:,}")

    # éªŒè¯æ•°æ®
    verify_query = """
    SELECT
      COUNT(*) as total_matches,
      MIN(timestamp) as earliest_match,
      MAX(timestamp) as latest_match,
      AVG(CASE WHEN winner = 3 THEN 1.0 ELSE 0.0 END) as dire_win_rate,
      AVG(ARRAY_LENGTH(radiant_heroes)) as avg_radiant_players,
      AVG(ARRAY_LENGTH(dire_heroes)) as avg_dire_players
    FROM `windy10v10ai.dota2.matches`
    """

    verify_result = client.query(verify_query).result()
    stats = list(verify_result)[0]

    print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
    print(f"   - æ€»å¯¹å±€æ•°: {stats['total_matches']:,}")
    print(f"   - æ—¶é—´èŒƒå›´: {stats['earliest_match']} ~ {stats['latest_match']}")
    print(f"   - Direèƒœç‡: {stats['dire_win_rate']:.2%}")
    print(f"   - Radiantå¹³å‡äººæ•°: {stats['avg_radiant_players']:.1f}")
    print(f"   - Direå¹³å‡äººæ•°: {stats['avg_dire_players']:.1f}")

    return stats['total_matches']

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='ä»GA4å¯¼å…¥å†å²å¯¹å±€æ•°æ®')
    parser.add_argument('--property-id', required=True, help='GA4 Property ID')
    parser.add_argument('--days', type=int, default=180, help='å¯¼å…¥æœ€è¿‘Nå¤©çš„æ•°æ®')
    parser.add_argument('--dry-run', action='store_true', help='åªç»Ÿè®¡ï¼Œä¸å®é™…å¯¼å…¥')

    args = parser.parse_args()

    import_ga4_data(
        property_id=args.property_id,
        days=args.days,
        dry_run=args.dry_run
    )
```

**ä½¿ç”¨æ–¹æ³•**ï¼š

```bash
# 1. å…ˆdry-runçœ‹æ•°æ®é‡
python ml/data/import_ga4_data.py \
  --property-id YOUR_PROPERTY_ID \
  --days 180 \
  --dry-run

# 2. ç¡®è®¤åæ‰§è¡Œå¯¼å…¥
python ml/data/import_ga4_data.py \
  --property-id YOUR_PROPERTY_ID \
  --days 180
```

---

## 3. æŒç»­æ•°æ®å†™å…¥ï¼ˆNestJSï¼‰

åœ¨å¯¼å…¥å†å²æ•°æ®åï¼Œæ–°å¯¹å±€è‡ªåŠ¨å†™å…¥ä¸“æœ‰è¡¨ã€‚

### BigQueryServiceå®ç°

```typescript
// api/src/bigquery/bigquery.service.ts
import { BigQuery } from '@google-cloud/bigquery';
import { Injectable, Logger } from '@nestjs/common';
import { GameEndMatchDto } from '../analytics/dto/game-end-dto';
import { GetHeroId } from '../analytics/data/hero-data';

@Injectable()
export class BigQueryService {
  private readonly logger = new Logger(BigQueryService.name);
  private bigquery = new BigQuery();
  private dataset = this.bigquery.dataset('dota2');
  private table = this.dataset.table('matches');

  async saveMatch(gameEnd: GameEndMatchDto): Promise<void> {
    try {
      // æå–Radiantè‹±é›„
      const radiantHeroes = gameEnd.players
        .filter(p => p.teamId === 2)
        .map(p => GetHeroId(p.heroName));

      // æå–Direè‹±é›„
      const direHeroes = gameEnd.players
        .filter(p => p.teamId === 3)
        .map(p => GetHeroId(p.heroName));

      // æ•°æ®éªŒè¯
      if (direHeroes.length !== 10) {
        this.logger.warn(
          `Invalid dire hero count: ${direHeroes.length}, match_id: ${gameEnd.matchId}`
        );
        return;
      }

      if (radiantHeroes.length < 1 || radiantHeroes.length > 10) {
        this.logger.warn(
          `Invalid radiant hero count: ${radiantHeroes.length}, match_id: ${gameEnd.matchId}`
        );
        return;
      }

      // æ„é€ è¡Œæ•°æ®
      const row = {
        match_id: gameEnd.matchId,
        timestamp: new Date().toISOString(),
        winner: gameEnd.winnerTeamId,
        radiant_heroes: radiantHeroes,
        dire_heroes: direHeroes,
        duration_msec: gameEnd.gameTimeMsec,
        game_version: gameEnd.version,
        difficulty: gameEnd.difficulty,
        server_type: 'production',
        recommendation_strategy: gameEnd.recommendationStrategy || null,  // 'baseline', 'xgboost_v1', etc.
        radiant_player_count: radiantHeroes.length,
        dire_player_count: direHeroes.length,
      };

      // æ’å…¥BigQuery
      await this.table.insert([row]);

      this.logger.log(
        `Match saved to BigQuery: ${gameEnd.matchId}, winner: ${gameEnd.winnerTeamId}`
      );
    } catch (error) {
      this.logger.error('Failed to save match to BigQuery', error);
      // ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œé¿å…å½±å“GA4æµç¨‹
    }
  }
}
```

### é›†æˆåˆ°Analytics Service

```typescript
// api/src/analytics/analytics.service.ts
import { BigQueryService } from '../bigquery/bigquery.service';

@Injectable()
export class AnalyticsService {
  constructor(
    private readonly bigQueryService: BigQueryService,
    // ... å…¶ä»–ä¾èµ–
  ) {}

  async gameEndMatch(gameEnd: GameEndMatchDto, serverType: SERVER_TYPE) {
    // ç°æœ‰ï¼šå‘é€åˆ°GA4
    await this.sendToGA4(gameEnd);

    // æ–°å¢ï¼šå†™å…¥BigQueryä¸“æœ‰è¡¨
    if (process.env.ENABLE_BIGQUERY_EXPORT === 'true') {
      await this.bigQueryService.saveMatch(gameEnd);
    }
  }
}
```

---

## 4. ç»Ÿä¸€çš„æ•°æ®åŠ è½½å™¨ï¼ˆMLè®­ç»ƒï¼‰

å¯¼å…¥åï¼Œåªéœ€è¦ä¸€ä¸ªç®€å•çš„æ•°æ®åŠ è½½å™¨ï¼š

```python
# ml/training/data_loader.py
from google.cloud import bigquery
import pandas as pd

class MatchDataLoader:
    def __init__(self, project_id='windy10v10ai'):
        self.client = bigquery.Client(project=project_id)

    def load_recent_matches(self, days=90):
        """ä»ä¸“æœ‰è¡¨åŠ è½½å¯¹å±€æ•°æ®"""
        query = f"""
        SELECT
          match_id,
          timestamp,
          winner,
          radiant_heroes,
          dire_heroes,
          duration_msec,
          game_version,
          difficulty,
          server_type,
          radiant_player_count,
          dire_player_count
        FROM `windy10v10ai.dota2.matches`
        WHERE timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
          AND radiant_player_count >= 1
          AND radiant_player_count <= 10
          AND dire_player_count = 10
        ORDER BY timestamp DESC
        """

        df = self.client.query(query).to_dataframe()
        return df

    def get_data_stats(self, df):
        """æ‰“å°æ•°æ®ç»Ÿè®¡"""
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»å¯¹å±€æ•°: {len(df):,}")
        print(f"   æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"   Direèƒœç‡: {(df['winner'] == 3).mean():.2%}")
        print(f"   Radiantå¹³å‡äººæ•°: {df['radiant_player_count'].mean():.1f}")

        # è‹±é›„é€‰æ‹©é¢‘ç‡
        from collections import Counter
        all_radiant = [h for heroes in df['radiant_heroes'] for h in heroes]
        all_dire = [h for heroes in df['dire_heroes'] for h in heroes]

        print(f"   Radiantæœ€å¸¸é€‰è‹±é›„: {Counter(all_radiant).most_common(5)}")
        print(f"   Direæœ€å¸¸é€‰è‹±é›„: {Counter(all_dire).most_common(5)}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    loader = MatchDataLoader()
    df = loader.load_recent_matches(days=90)
    loader.get_data_stats(df)
```

---

## 5. æ‰§è¡Œæ¸…å•

### æ­¥éª¤1: åˆ›å»ºè¡¨ï¼ˆ10åˆ†é’Ÿï¼‰
```bash
# åœ¨BigQueryæ§åˆ¶å°æ‰§è¡Œå»ºè¡¨SQL
# æˆ–ä½¿ç”¨bqå‘½ä»¤è¡Œ
bq mk --table \
  windy10v10ai:dota2.matches \
  ml/data/schema.json
```

### æ­¥éª¤2: å¯¼å…¥å†å²æ•°æ®ï¼ˆ30åˆ†é’Ÿï¼‰
```bash
# æ–¹å¼A: ç›´æ¥æ‰§è¡ŒSQL
bq query --use_legacy_sql=false < ml/data/import_ga4_to_dedicated_table.sql

# æ–¹å¼B: Pythonè„šæœ¬
python ml/data/import_ga4_data.py --property-id YOUR_ID --dry-run
python ml/data/import_ga4_data.py --property-id YOUR_ID
```

### æ­¥éª¤3: éªŒè¯æ•°æ®ï¼ˆ5åˆ†é’Ÿï¼‰
```sql
-- åœ¨BigQueryæ§åˆ¶å°æ‰§è¡Œ
SELECT
  COUNT(*) as total,
  MIN(timestamp) as earliest,
  MAX(timestamp) as latest,
  AVG(CASE WHEN winner = 3 THEN 1.0 ELSE 0.0 END) as dire_win_rate
FROM `windy10v10ai.dota2.matches`;
```

### æ­¥éª¤4: é…ç½®æŒç»­å†™å…¥ï¼ˆ20åˆ†é’Ÿï¼‰
```bash
# 1. å®ç°BigQueryServiceï¼ˆå·²æœ‰ä»£ç ï¼‰
# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export ENABLE_BIGQUERY_EXPORT=true

# 3. éƒ¨ç½²åˆ°Firebase Functions
firebase deploy --only functions:client
```

---

## 6. é¢„æœŸæ•°æ®é‡

å‡è®¾ï¼š
- æ¯æœˆå¯¹å±€ï¼š100,000åœº
- å†å²æ•°æ®ï¼š6ä¸ªæœˆ
- æ€»æ•°æ®é‡ï¼šçº¦600,000åœºå¯¹å±€

**BigQueryæˆæœ¬ä¼°ç®—**ï¼š
- å­˜å‚¨ï¼š600k Ã— 500å­—èŠ‚ â‰ˆ 300MB â†’ $0.006/æœˆ
- æŸ¥è¯¢ï¼ˆè®­ç»ƒï¼‰ï¼šæ¯æ¬¡æ‰«æ300MB â†’ å…è´¹é¢åº¦å†…ï¼ˆ1TB/æœˆå…è´¹ï¼‰

---

## ä¼˜åŠ¿æ€»ç»“

âœ… **ç»Ÿä¸€æ•°æ®æº**ï¼šå†å²æ•°æ®å’Œæ–°æ•°æ®åœ¨åŒä¸€å¼ è¡¨ï¼Œæ— éœ€ä¸¤å¥—åŠ è½½å™¨
âœ… **é«˜æ•ˆæŸ¥è¯¢**ï¼šåˆ†åŒº+èšç°‡ï¼ŒæŸ¥è¯¢é€Ÿåº¦å¿«
âœ… **æ•°æ®è´¨é‡**ï¼šå¯¼å…¥æ—¶è¿‡æ»¤ï¼Œç¡®ä¿è®­ç»ƒæ•°æ®å¹²å‡€
âœ… **å¯æ‰©å±•æ€§**ï¼šæ–°å­—æ®µï¼ˆå¦‚ç©å®¶ç­‰çº§ï¼‰å¯ä»¥è½»æ¾æ·»åŠ 
âœ… **æˆæœ¬ä½**ï¼šå®Œå…¨åœ¨BigQueryå…è´¹é¢åº¦å†…
