# AI è‹±é›„æ¨èç³»ç»Ÿ - åˆ†é˜¶æ®µå®æ–½è®¡åˆ’ v2

## æ¦‚è§ˆ

æœ¬æ–‡æ¡£å°†å®æ–½å·¥ä½œåˆ†ä¸ºä¸¤ä¸ªé˜¶æ®µï¼š

- **Phase 1**: å¿«é€Ÿå®éªŒéªŒè¯ï¼ˆå»ºç«‹ä¸“æœ‰è¡¨ï¼Œå¯¼å…¥å†å²æ•°æ®ï¼Œè®­ç»ƒå¹¶éƒ¨ç½²æ¨¡å‹ï¼‰
- **Phase 2**: æŒç»­ä¼˜åŒ–ï¼ˆæ¨¡å‹è°ƒå‚ã€è‡ªåŠ¨é‡è®­ç»ƒã€ç›‘æ§ï¼‰

**å…³é”®ç­–ç•¥**ï¼šå…ˆå»ºä¸“æœ‰ BigQuery è¡¨å¹¶å¯¼å…¥ GA4 å†å²æ•°æ®ï¼Œä¹‹åæ‰€æœ‰è®­ç»ƒéƒ½ç”¨è¿™ä¸€å¼ è¡¨ã€‚

---

## Phase 1: å¿«é€Ÿå®éªŒéªŒè¯ï¼ˆ2-3 å‘¨ï¼‰

**ç›®æ ‡**ï¼šå»ºç«‹ä¸“æœ‰æ•°æ®è¡¨ï¼Œå¯¼å…¥å†å²æ•°æ®ï¼Œå¿«é€Ÿè®­ç»ƒæ¨¡å‹å¹¶éªŒè¯æ–¹æ¡ˆå¯è¡Œæ€§

### Phase 1.0: æ•°æ®åŸºç¡€è®¾æ–½ï¼ˆå…ˆå†³æ¡ä»¶ï¼Œ2-3 å°æ—¶ï¼‰

#### Issue #P1-0: åˆ›å»º BigQuery ä¸“æœ‰è¡¨å¹¶å¯¼å…¥å†å²æ•°æ®

**ä¼˜å…ˆçº§**ï¼šP0ï¼ˆé˜»å¡æ‰€æœ‰åç»­ä»»åŠ¡ï¼‰
**é¢„è®¡å·¥æ—¶**ï¼š2-3 å°æ—¶

**ä»»åŠ¡æè¿°**ï¼š

- [ ] åˆ›å»º`dota2.matches`ä¸“æœ‰è¡¨
- [ ] ç¼–å†™ä» GA4 å¯¼å…¥å†å²æ•°æ®çš„ SQL
- [ ] æ‰§è¡Œæ•°æ®å¯¼å…¥ï¼ˆæœ€è¿‘ 6 ä¸ªæœˆæ•°æ®ï¼‰
- [ ] éªŒè¯æ•°æ®è´¨é‡å’Œæ•°é‡

**è¯¦ç»†æ­¥éª¤**ï¼šè§ [BIGQUERY_SETUP.md](./BIGQUERY_SETUP.md)

**å…³é”® SQL**ï¼š

```sql
-- 1. å»ºè¡¨
CREATE TABLE `windy10v10ai.dota2.matches` (
  match_id STRING NOT NULL,
  timestamp TIMESTAMP NOT NULL,
  winner INT64 NOT NULL,
  radiant_heroes ARRAY<INT64> NOT NULL,
  dire_heroes ARRAY<INT64> NOT NULL,
  duration_msec INT64,
  game_version STRING,
  difficulty INT64,
  server_type STRING,
  radiant_player_count INT64,
  dire_player_count INT64
)
PARTITION BY DATE(timestamp)
CLUSTER BY winner, difficulty;

-- 2. å¯¼å…¥æ•°æ®ï¼ˆè§BIGQUERY_SETUP.mdä¸­çš„å®Œæ•´SQLï¼‰
INSERT INTO `windy10v10ai.dota2.matches` ...
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] ä¸“æœ‰è¡¨åˆ›å»ºæˆåŠŸ
- [ ] è‡³å°‘å¯¼å…¥ 50,000 åœºå†å²å¯¹å±€æ•°æ®
- [ ] Dire èƒœç‡çº¦ 20%
- [ ] Radiant å¹³å‡äººæ•°åœ¨ 1-10 èŒƒå›´å†…
- [ ] Dire å›ºå®š 10 ä¸ªè‹±é›„

**æ³¨æ„**ï¼šæŒç»­æ•°æ®å†™å…¥åŠŸèƒ½å·²æ‹†åˆ†åˆ° [Issue #P1-0.1](./ISSUE_P1-0.1.md)ï¼Œåœ¨ P1-0 å®Œæˆåæ‰§è¡Œ

**ä¸ºä»€ä¹ˆå…ˆåšè¿™ä¸€æ­¥ï¼Ÿ**
âœ… ç»Ÿä¸€æ•°æ®æºï¼Œåç»­æ‰€æœ‰è®­ç»ƒéƒ½ç”¨åŒä¸€å¼ è¡¨
âœ… åˆ©ç”¨ç°æœ‰ GA4 å†å²æ•°æ®ï¼Œæ— éœ€ç­‰å¾…æ–°æ•°æ®æ”¶é›†
âœ… æ•°æ®å¯¼å…¥ä¸€æ¬¡æ€§å®Œæˆï¼Œè®­ç»ƒæ—¶ç›´æ¥æŸ¥è¯¢

---

#### Issue #P1-0.1: é…ç½®æŒç»­æ•°æ®å†™å…¥ï¼ˆæ–°å¯¹å±€è‡ªåŠ¨å†™å…¥ï¼‰

**ä¼˜å…ˆçº§**ï¼šP1ï¼ˆåœ¨ P1-0 ä¹‹åæ‰§è¡Œï¼‰
**é¢„è®¡å·¥æ—¶**ï¼š4-6 å°æ—¶
**ä¾èµ–**ï¼š#P1-0

**ä»»åŠ¡æè¿°**ï¼š

- [ ] å®ç° BigQueryServiceï¼ˆå†™å…¥æœåŠ¡ï¼‰
- [ ] é›†æˆåˆ° AnalyticsServiceï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡æ§åˆ¶ï¼‰
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•å’Œé”™è¯¯å¤„ç†
- [ ] éƒ¨ç½²å¹¶éªŒè¯æ•°æ®å†™å…¥

**è¯¦ç»†æ­¥éª¤**ï¼šè§ [ISSUE_P1-0.1.md](./ISSUE_P1-0.1.md)

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] BigQueryService å¯ä»¥æˆåŠŸå†™å…¥æµ‹è¯•æ•°æ®
- [ ] æ•°æ®éªŒè¯é€»è¾‘æ­£ç¡®ï¼ˆè¿‡æ»¤æ— æ•ˆæ•°æ®ï¼‰
- [ ] å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡`ENABLE_BIGQUERY_EXPORT`æ§åˆ¶å¯ç”¨/ç¦ç”¨
- [ ] éƒ¨ç½²åæ–°å¯¹å±€æ•°æ®èƒ½æ­£ç¡®å†™å…¥ BigQuery è¡¨

**ä¸ºä»€ä¹ˆåœ¨ P1-0 ä¹‹åï¼Ÿ**
âœ… è¡¨å¿…é¡»å…ˆåˆ›å»ºï¼Œæ‰èƒ½å†™å…¥æ•°æ®
âœ… å†å²æ•°æ®å¯¼å…¥æ˜¯é˜»å¡é¡¹ï¼Œå¿…é¡»ä¼˜å…ˆå®Œæˆ
âœ… æŒç»­å†™å…¥å¯ä»¥åœ¨éªŒè¯å†å²æ•°æ®åå†é…ç½®

---

### Phase 1.1: ç¯å¢ƒå‡†å¤‡ï¼ˆç¬¬ 1 å‘¨ï¼Œ7 å°æ—¶ï¼‰

#### Issue #P1-1: åˆ›å»º Python è®­ç»ƒé¡¹ç›®ç»“æ„

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š3 å°æ—¶

**ä»»åŠ¡æè¿°**ï¼š

- [ ] åˆ›å»º`ml/training/`ç›®å½•ç»“æ„
- [ ] åˆ›å»º`requirements.txt`
- [ ] åˆ›å»º`README.md`ï¼ˆç¯å¢ƒè®¾ç½®æŒ‡å—ï¼‰
- [ ] æ·»åŠ `.gitignore`

**ç›®å½•ç»“æ„**ï¼š

```
ml/
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ README.md                  # ç¯å¢ƒè®¾ç½®æŒ‡å—
â”‚   â”œâ”€â”€ requirements.txt           # Pythonä¾èµ–
â”‚   â”œâ”€â”€ data_loader.py             # ä¸“æœ‰è¡¨æ•°æ®åŠ è½½å™¨
â”‚   â”œâ”€â”€ feature_engineering.py     # ç‰¹å¾å·¥ç¨‹
â”‚   â”œâ”€â”€ train.py                   # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ evaluate.py                # è¯„ä¼°è„šæœ¬
â”‚   â””â”€â”€ config.yaml                # è®­ç»ƒé…ç½®
â””â”€â”€ inference/
    â”œâ”€â”€ main.py                    # FastAPIåº”ç”¨
    â”œâ”€â”€ feature_engineering.py     # ç‰¹å¾ç¼–ç ï¼ˆå¤ç”¨ï¼‰
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ model.json                 # è®­ç»ƒå¥½çš„æ¨¡å‹
    â””â”€â”€ README.md
```

**requirements.txt**ï¼š

```
google-cloud-bigquery==3.14.0
pandas==2.1.4
numpy==1.26.2
xgboost==2.0.3
scikit-learn==1.3.2
pyyaml==6.0.1
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] ç›®å½•ç»“æ„å®Œæ•´
- [ ] requirements.txt å¯ä»¥æˆåŠŸå®‰è£…
- [ ] README åŒ…å«ç¯å¢ƒè®¾ç½®è¯´æ˜

---

#### Issue #P1-2: å®ç°ä¸“æœ‰è¡¨æ•°æ®åŠ è½½å™¨

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š2 å°æ—¶
**ä¾èµ–**ï¼š#P1-0, #P1-1

**ä»»åŠ¡æè¿°**ï¼š

- [ ] å®ç°`data_loader.py`ä»ä¸“æœ‰è¡¨åŠ è½½æ•°æ®
- [ ] æ”¯æŒæŒ‰æ—¶é—´èŒƒå›´æŸ¥è¯¢
- [ ] æ·»åŠ æ•°æ®ç»Ÿè®¡åŠŸèƒ½
- [ ] æœ¬åœ°æµ‹è¯•ï¼ˆéœ€è¦ GCP è®¤è¯ï¼‰

**å…³é”®ä»£ç **ï¼š

```python
# ml/training/data_loader.py
from google.cloud import bigquery
import pandas as pd
from collections import Counter

class MatchDataLoader:
    def __init__(self, project_id='windy10v10ai'):
        self.client = bigquery.Client(project=project_id)

    def load_recent_matches(self, days=90):
        """ä»ä¸“æœ‰è¡¨åŠ è½½å¯¹å±€æ•°æ®"""
        query = f"""
        SELECT
          match_id,
          timestamp,
          winner,
          radiant_heroes,
          dire_heroes,
          duration_msec,
          game_version,
          difficulty,
          server_type,
          radiant_player_count,
          dire_player_count
        FROM `windy10v10ai.dota2.matches`
        WHERE timestamp > TIMESTAMP_SUB(CURRENT_TIMESTAMP(), INTERVAL {days} DAY)
          AND radiant_player_count >= 1
          AND radiant_player_count <= 10
          AND dire_player_count = 10
        ORDER BY timestamp DESC
        """

        df = self.client.query(query).to_dataframe()
        return df

    def get_data_stats(self, df):
        """æ‰“å°æ•°æ®ç»Ÿè®¡"""
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»å¯¹å±€æ•°: {len(df):,}")
        print(f"   æ—¶é—´èŒƒå›´: {df['timestamp'].min()} ~ {df['timestamp'].max()}")
        print(f"   Direèƒœç‡: {(df['winner'] == 3).mean():.2%}")
        print(f"   Radiantå¹³å‡äººæ•°: {df['radiant_player_count'].mean():.1f}")

        # è‹±é›„é€‰æ‹©é¢‘ç‡
        all_radiant = [h for heroes in df['radiant_heroes'] for h in heroes]
        all_dire = [h for heroes in df['dire_heroes'] for h in heroes]

        print(f"\nğŸ¯ æœ€å¸¸é€‰è‹±é›„:")
        print(f"   Radiant: {Counter(all_radiant).most_common(5)}")
        print(f"   Dire: {Counter(all_dire).most_common(5)}")

        return {
            'total': len(df),
            'dire_win_rate': (df['winner'] == 3).mean(),
            'avg_radiant_players': df['radiant_player_count'].mean()
        }

# æµ‹è¯•
if __name__ == '__main__':
    loader = MatchDataLoader()
    df = loader.load_recent_matches(days=90)
    stats = loader.get_data_stats(df)
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] å¯ä»¥æˆåŠŸä»ä¸“æœ‰è¡¨åŠ è½½æ•°æ®
- [ ] DataFrame åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µ
- [ ] æ•°æ®é‡ > 50,000 åœºå¯¹å±€ï¼ˆå–å†³äºå¯¼å…¥çš„å†å²æ•°æ®ï¼‰
- [ ] æœ‰è¯¦ç»†çš„æ•°æ®è´¨é‡ç»Ÿè®¡è¾“å‡º
- [ ] æŸ¥è¯¢é€Ÿåº¦ < 5 ç§’

---

#### Issue #P1-3: å®ç°ç‰¹å¾å·¥ç¨‹æ¨¡å—

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š4 å°æ—¶
**ä¾èµ–**ï¼š#P1-2

**ä»»åŠ¡æè¿°**ï¼š

- [ ] å®ç°`encode_radiant()`å‡½æ•°ï¼ˆè®¡æ•°å‘é‡ï¼‰
- [ ] å®ç°`encode_dire()`å‡½æ•°ï¼ˆMulti-hotï¼‰
- [ ] å®ç°æ ·æœ¬ç”Ÿæˆé€»è¾‘ï¼ˆæ¯åœºå¯¹å±€ 10 ä¸ªæ ·æœ¬ï¼‰
- [ ] æ·»åŠ å•å…ƒæµ‹è¯•
- [ ] éªŒè¯ç‰¹å¾ç»´åº¦ï¼ˆ260 ç»´ï¼‰

**ä»£ç æ¡†æ¶**ï¼š

```python
# ml/training/feature_engineering.py
import numpy as np

HERO_COUNT = 130

def encode_radiant(hero_ids: list) -> np.ndarray:
    """
    è®¡æ•°å‘é‡ç¼–ç ï¼ˆå¯é‡å¤ï¼‰
    è¾“å…¥ï¼š[3, 3, 7, 7, 7] ï¼ˆRadiantæœ‰5ä¸ªç©å®¶ï¼‰
    è¾“å‡ºï¼š130ç»´å‘é‡ï¼Œç´¢å¼•2æœ‰2ä¸ªï¼Œç´¢å¼•6æœ‰3ä¸ª
    """
    vector = np.zeros(HERO_COUNT, dtype=np.int32)
    for hero_id in hero_ids:
        if 1 <= hero_id <= HERO_COUNT:
            vector[hero_id - 1] += 1
    return vector

def encode_dire(hero_ids: list) -> np.ndarray:
    """
    Multi-hotç¼–ç ï¼ˆä¸å¯é‡å¤ï¼‰
    è¾“å…¥ï¼š[3, 7, 12]
    è¾“å‡ºï¼š130ç»´å‘é‡ï¼Œç´¢å¼•2ã€6ã€11ä¸º1ï¼Œå…¶ä½™ä¸º0
    """
    vector = np.zeros(HERO_COUNT, dtype=np.int32)
    for hero_id in hero_ids:
        if 1 <= hero_id <= HERO_COUNT:
            vector[hero_id - 1] = 1
    return vector

def generate_training_samples(match_row):
    """
    ä»ä¸€åœºå¯¹å±€ç”Ÿæˆ10ä¸ªè®­ç»ƒæ ·æœ¬

    è¿”å›ï¼š
    - X: (10, 260) ç‰¹å¾çŸ©é˜µ
    - y: (10, 130) æ ‡ç­¾çŸ©é˜µï¼ˆone-hotï¼‰
    - weights: (10,) æ ·æœ¬æƒé‡
    """
    radiant_vec = encode_radiant(match_row['radiant_heroes'])
    dire_heroes = match_row['dire_heroes']
    is_dire_win = (match_row['winner'] == 3)

    X_list = []
    y_list = []
    weights = []

    for i in range(10):
        # è¾“å…¥ï¼šradiant + direå‰iä¸ªè‹±é›„
        dire_picked = dire_heroes[:i]
        dire_vec = encode_dire(dire_picked)
        X = np.concatenate([radiant_vec, dire_vec])

        # æ ‡ç­¾ï¼šç¬¬i+1ä¸ªè‹±é›„ï¼ˆone-hotï¼‰
        y_hero = dire_heroes[i]
        y = np.zeros(HERO_COUNT)
        y[y_hero - 1] = 1

        # æƒé‡ï¼šDireèµ¢äº†ï¼Œç»™æ›´é«˜æƒé‡
        weight = 1.0 if is_dire_win else 0.25

        X_list.append(X)
        y_list.append(y)
        weights.append(weight)

    return np.array(X_list), np.array(y_list), np.array(weights)

def prepare_dataset(df):
    """å°†æ‰€æœ‰å¯¹å±€è½¬æ¢ä¸ºè®­ç»ƒæ•°æ®"""
    all_X = []
    all_y = []
    all_weights = []

    for _, row in df.iterrows():
        X, y, weights = generate_training_samples(row)
        all_X.append(X)
        all_y.append(y)
        all_weights.append(weights)

    X = np.vstack(all_X)
    y = np.vstack(all_y)
    weights = np.concatenate(all_weights)

    # è½¬æ¢ä¸ºç±»åˆ«æ ‡ç­¾ï¼ˆè€Œéone-hotï¼‰
    y_labels = np.argmax(y, axis=1)

    print(f"æ€»æ ·æœ¬æ•°: {len(X)}")
    print(f"ç‰¹å¾ç»´åº¦: {X.shape[1]}")
    print(f"ç±»åˆ«æ•°: {len(np.unique(y_labels))}")

    return X, y_labels, weights
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] å•å…ƒæµ‹è¯•é€šè¿‡ç‡ 100%
- [ ] å¯ä»¥ä»æµ‹è¯•æ•°æ®ç”Ÿæˆæ­£ç¡®çš„æ ·æœ¬
- [ ] ç‰¹å¾å‘é‡ç»´åº¦=260
- [ ] æ ‡ç­¾èŒƒå›´åœ¨[0, 129]

---

### Phase 1.2: æ¨¡å‹è®­ç»ƒï¼ˆç¬¬ 2 å‘¨ï¼Œ12 å°æ—¶ï¼‰

#### Issue #P1-4: å®ç° XGBoost è®­ç»ƒè„šæœ¬

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š6 å°æ—¶
**ä¾èµ–**ï¼š#P1-3

**ä»»åŠ¡æè¿°**ï¼š

- [ ] å®ç°`train.py`ä¸»è„šæœ¬
- [ ] æ”¯æŒé…ç½®æ–‡ä»¶ï¼ˆ`config.yaml`ï¼‰
- [ ] å®ç°è®­ç»ƒ/éªŒè¯é›†åˆ’åˆ†
- [ ] å®ç°æ—©åœï¼ˆearly stoppingï¼‰
- [ ] ä¿å­˜è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹æ–‡ä»¶
- [ ] æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ”¯æŒ

**config.yaml**ï¼š

```yaml
data:
  days: 90 # ä½¿ç”¨æœ€è¿‘Nå¤©çš„æ•°æ®
  train_ratio: 0.8 # è®­ç»ƒé›†æ¯”ä¾‹

model:
  max_depth: 8
  learning_rate: 0.1
  n_estimators: 200
  subsample: 0.8
  colsample_bytree: 0.8
  scale_pos_weight: 4 # å¤„ç†20%èƒœç‡ä¸å¹³è¡¡

training:
  early_stopping_rounds: 20
  eval_metric: mlogloss
  verbose_eval: 10

output:
  model_path: models/hero_recommendation_v1.json
  log_path: logs/training.log
```

**train.py**ï¼š

```python
# ml/training/train.py
import xgboost as xgb
from sklearn.model_selection import train_test_split
import yaml
import argparse
from datetime import datetime

from data_loader import MatchDataLoader
from feature_engineering import prepare_dataset

def train_model(config):
    # åŠ è½½æ•°æ®
    print("åŠ è½½æ•°æ®...")
    loader = MatchDataLoader(project_id='windy10v10ai')
    df = loader.load_recent_matches(days=config['data']['days'])

    # ç‰¹å¾å·¥ç¨‹
    print("ç”Ÿæˆè®­ç»ƒæ ·æœ¬...")
    X, y, weights = prepare_dataset(df)

    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    X_train, X_val, y_train, y_val, w_train, w_val = train_test_split(
        X, y, weights,
        test_size=1-config['data']['train_ratio'],
        random_state=42
    )

    # åˆ›å»ºDMatrix
    dtrain = xgb.DMatrix(X_train, label=y_train, weight=w_train)
    dval = xgb.DMatrix(X_val, label=y_val, weight=w_val)

    # è®­ç»ƒå‚æ•°
    params = {
        'objective': 'multi:softprob',
        'num_class': 130,
        **config['model']
    }

    # è®­ç»ƒ
    print("å¼€å§‹è®­ç»ƒ...")
    evals = [(dtrain, 'train'), (dval, 'val')]
    model = xgb.train(
        params,
        dtrain,
        num_boost_round=config['model']['n_estimators'],
        evals=evals,
        early_stopping_rounds=config['training']['early_stopping_rounds'],
        verbose_eval=config['training']['verbose_eval']
    )

    # ä¿å­˜æ¨¡å‹
    model_path = config['output']['model_path']
    model.save_model(model_path)
    print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {model_path}")

    return model

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--config', default='config.yaml')
    args = parser.parse_args()

    with open(args.config, 'r') as f:
        config = yaml.safe_load(f)

    train_model(config)
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] å¯ä»¥æˆåŠŸè®­ç»ƒæ¨¡å‹
- [ ] è®­ç»ƒè¿‡ç¨‹æœ‰è¿›åº¦è¾“å‡º
- [ ] æ¨¡å‹ä¿å­˜ä¸º JSON æ ¼å¼
- [ ] éªŒè¯é›† loss ä¸‹é™
- [ ] æœ‰è®­ç»ƒæ—¥å¿—è®°å½•

---

#### Issue #P1-5: é¦–æ¬¡æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š6 å°æ—¶
**ä¾èµ–**ï¼š#P1-4

**ä»»åŠ¡æè¿°**ï¼š

- [ ] è¿è¡Œé¦–æ¬¡è®­ç»ƒï¼ˆä½¿ç”¨çœŸå® GA4 æ•°æ®ï¼‰
- [ ] å®ç°ç®€å•çš„è¯„ä¼°è„šæœ¬
- [ ] è®°å½• Top-1/Top-3/Top-5 å‡†ç¡®ç‡
- [ ] åˆ†æç‰¹å¾é‡è¦æ€§
- [ ] è®°å½•è®­ç»ƒç»“æœå’Œå‚æ•°

**evaluate.py**ï¼š

```python
# ml/training/evaluate.py
import xgboost as xgb
import numpy as np

def evaluate_model(model, X_val, y_val):
    """è¯„ä¼°æ¨¡å‹"""
    dval = xgb.DMatrix(X_val)
    probs = model.predict(dval)  # (n_samples, 130)

    # Top-Kå‡†ç¡®ç‡
    top1_acc = (np.argmax(probs, axis=1) == y_val).mean()
    top3_acc = np.mean([y in np.argsort(p)[-3:] for p, y in zip(probs, y_val)])
    top5_acc = np.mean([y in np.argsort(p)[-5:] for p, y in zip(probs, y_val)])

    print(f"Top-1å‡†ç¡®ç‡: {top1_acc:.2%}")
    print(f"Top-3å‡†ç¡®ç‡: {top3_acc:.2%}")
    print(f"Top-5å‡†ç¡®ç‡: {top5_acc:.2%}")

    return {
        'top1': top1_acc,
        'top3': top3_acc,
        'top5': top5_acc
    }
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] æ¨¡å‹è®­ç»ƒæˆåŠŸå®Œæˆ
- [ ] Top-1 å‡†ç¡®ç‡ > 2%ï¼ˆéšæœºçŒœæµ‹ä¸º 0.77%ï¼‰
- [ ] Top-3 å‡†ç¡®ç‡ > 5%
- [ ] æœ‰ç‰¹å¾é‡è¦æ€§åˆ†æ
- [ ] æœ‰å®Œæ•´çš„å®éªŒè®°å½•

---

### Phase 1.3: æ¨ç†æœåŠ¡éƒ¨ç½²ï¼ˆç¬¬ 3 å‘¨ï¼Œ16 å°æ—¶ï¼‰

#### Issue #P1-6: åˆ›å»º FastAPI æ¨ç†æœåŠ¡

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š6 å°æ—¶
**ä¾èµ–**ï¼š#P1-5

**ä»»åŠ¡æè¿°**ï¼š

- [ ] åˆ›å»º`ml/inference/`ç›®å½•
- [ ] å®ç°`main.py`ï¼ˆFastAPI åº”ç”¨ï¼‰
- [ ] å®ç°`/recommend` endpoint
- [ ] å®ç°`/health` endpoint
- [ ] å¤åˆ¶`feature_engineering.py`
- [ ] æœ¬åœ°æµ‹è¯•

**main.py**ï¼š

```python
# ml/inference/main.py
from fastapi import FastAPI
import xgboost as xgb
import numpy as np
from feature_engineering import encode_radiant, encode_dire

app = FastAPI(title="Dota2 Hero Recommendation API")

# åŠ è½½æ¨¡å‹
model = xgb.Booster()
model.load_model("model.json")

@app.post("/recommend")
def recommend(request: dict):
    """
    æ¨è10ä¸ªDireè‹±é›„

    è¯·æ±‚ï¼š{"radiant_heroes": [3, 3, 7, 12, 15]}
    å“åº”ï¼š{"picks": [52, 89, 14, ...]}
    """
    radiant_heroes = request["radiant_heroes"]
    radiant_vec = encode_radiant(radiant_heroes)

    dire_picked = []
    recommendations = []

    for _ in range(10):
        # æ„é€ ç‰¹å¾
        dire_vec = encode_dire(dire_picked)
        feature = np.concatenate([radiant_vec, dire_vec])

        # é¢„æµ‹
        dmatrix = xgb.DMatrix([feature])
        scores = model.predict(dmatrix)[0]

        # å±è”½å·²é€‰è‹±é›„
        for hero_id in dire_picked:
            scores[hero_id - 1] = -999

        # é€‰æ‹©æœ€é«˜åˆ†
        best_hero = int(np.argmax(scores) + 1)
        recommendations.append(best_hero)
        dire_picked.append(best_hero)

    return {"picks": recommendations}

@app.get("/health")
def health():
    return {"status": "healthy", "model": "hero_recommendation_v1"}
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] FastAPI å¯ä»¥æœ¬åœ°å¯åŠ¨
- [ ] `/recommend`è¿”å› 10 ä¸ªè‹±é›„ ID
- [ ] `/health`æ­£å¸¸å“åº”
- [ ] æ¨ç†å»¶è¿Ÿ < 100ms

---

#### Issue #P1-7: åˆ›å»º Dockerfile å¹¶éƒ¨ç½²åˆ° Cloud Run

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š6 å°æ—¶
**ä¾èµ–**ï¼š#P1-6

**ä»»åŠ¡æè¿°**ï¼š

- [ ] ç¼–å†™`Dockerfile`
- [ ] ä¼˜åŒ–é•œåƒå¤§å°
- [ ] æœ¬åœ°æµ‹è¯•å®¹å™¨
- [ ] åˆ›å»º`deploy.sh`è„šæœ¬
- [ ] éƒ¨ç½²åˆ° Cloud Run
- [ ] é…ç½®ç¯å¢ƒå˜é‡
- [ ] è¿›è¡Œå‹åŠ›æµ‹è¯•

**Dockerfile**ï¼š

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY main.py feature_engineering.py model.json ./

EXPOSE 8080

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

**deploy.sh**ï¼š

```bash
#!/bin/bash
PROJECT_ID="windy10v10ai"
SERVICE_NAME="hero-recommendation"
REGION="asia-northeast1"

# æ„å»ºé•œåƒ
gcloud builds submit --tag gcr.io/${PROJECT_ID}/${SERVICE_NAME}

# éƒ¨ç½²
gcloud run deploy ${SERVICE_NAME} \
  --image gcr.io/${PROJECT_ID}/${SERVICE_NAME} \
  --platform managed \
  --region ${REGION} \
  --allow-unauthenticated \
  --memory 512Mi \
  --cpu 1 \
  --max-instances 10 \
  --min-instances 1
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] Cloud Run æœåŠ¡æˆåŠŸéƒ¨ç½²
- [ ] è·å¾—å…¬ç½‘ URL
- [ ] å»¶è¿Ÿ < 200msï¼ˆP95ï¼‰
- [ ] å¯ä»¥å¤„ç† 10 å¹¶å‘è¯·æ±‚

---

#### Issue #P1-8: æ¸¸æˆ Bot é›†æˆæ¨è API

**ä¼˜å…ˆçº§**ï¼šP0
**é¢„è®¡å·¥æ—¶**ï¼š4 å°æ—¶
**ä¾èµ–**ï¼š#P1-7

**ä»»åŠ¡æè¿°**ï¼š

- [ ] åœ¨ Bot ä»£ç ä¸­æ·»åŠ  HTTP è¯·æ±‚
- [ ] BP é˜¶æ®µè°ƒç”¨æ¨è API
- [ ] æ·»åŠ  fallback æœºåˆ¶ï¼ˆAPI å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤é€»è¾‘ï¼‰
- [ ] æ·»åŠ  feature flag æ§åˆ¶
- [ ] æ·»åŠ æ—¥å¿—è®°å½•

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] Bot å¯ä»¥æˆåŠŸè°ƒç”¨ Cloud Run API
- [ ] API å¤±è´¥æ—¶ä¸å½±å“æ¸¸æˆ
- [ ] æœ‰æ—¥å¿—è®°å½•æ¨èç»“æœ
- [ ] å¯ä»¥é€šè¿‡é…ç½®å¼€å…³å¯ç”¨/ç¦ç”¨

---

### Phase 1.4: ç°åº¦æµ‹è¯•ï¼ˆæŒç»­ 1 å‘¨ï¼Œ4 å°æ—¶ï¼‰

#### Issue #P1-9: ç°åº¦æµ‹è¯•å’Œæ•ˆæœè¯„ä¼°

**ä¼˜å…ˆçº§**ï¼šP1
**é¢„è®¡å·¥æ—¶**ï¼š4 å°æ—¶
**ä¾èµ–**ï¼š#P1-8

**ä»»åŠ¡æè¿°**ï¼š

- [ ] é…ç½® 10%æµé‡ä½¿ç”¨ AI æ¨è
- [ ] æ”¶é›†è‡³å°‘ 100 åœºå¯¹å±€æ•°æ®
- [ ] ç»Ÿè®¡ AI æ¨èçš„ Dire èƒœç‡
- [ ] ä¸å†å²åŸºçº¿å¯¹æ¯”
- [ ] åˆ†ææ•ˆæœå¹¶å†³å®šæ˜¯å¦å…¨é‡

**SQL ç›‘æ§æŸ¥è¯¢**ï¼š

```sql
-- ç»Ÿè®¡ä¸åŒæ¨èç­–ç•¥çš„èƒœç‡å¯¹æ¯”
-- æ³¨æ„ï¼šéœ€è¦åœ¨game_end_matchäº‹ä»¶ä¸­æ·»åŠ recommendation_strategyå‚æ•°
-- å¯èƒ½çš„å€¼: 'baseline', 'xgboost_v1', 'xgboost_v2', 'random' ç­‰
SELECT
  recommendation_strategy,
  COUNT(*) as total_matches,
  SUM(CASE WHEN winner = 3 THEN 1 ELSE 0 END) as dire_wins,
  AVG(CASE WHEN winner = 3 THEN 1.0 ELSE 0.0 END) as dire_win_rate
FROM (
  SELECT
    (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'match_id') as match_id,
    (SELECT value.int_value FROM UNNEST(event_params) WHERE key = 'winner_team_id') as winner,
    (SELECT value.string_value FROM UNNEST(event_params) WHERE key = 'recommendation_strategy') as recommendation_strategy
  FROM `windy10v10ai.analytics_<property_id>.events_*`
  WHERE event_name = 'game_end_match'
    AND _TABLE_SUFFIX BETWEEN FORMAT_DATE('%Y%m%d', DATE_SUB(CURRENT_DATE(), INTERVAL 7 DAY))
                          AND FORMAT_DATE('%Y%m%d', CURRENT_DATE())
)
WHERE recommendation_strategy IS NOT NULL
GROUP BY recommendation_strategy
ORDER BY dire_win_rate DESC;
```

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] è‡³å°‘è¿è¡Œ 100 åœº AI æ¨èå¯¹å±€
- [ ] æœ‰èƒœç‡ç»Ÿè®¡æ•°æ®
- [ ] æ— ä¸¥é‡ Bug æˆ–å´©æºƒ
- [ ] å†³ç­–ï¼šæ˜¯å¦å…¨é‡ä¸Šçº¿

---

### Phase 1 æ€»ç»“

**é¢„è®¡æ€»å·¥æ—¶**ï¼š52 å°æ—¶ â‰ˆ 6-7 ä¸ªå·¥ä½œæ—¥
**é¢„è®¡æ—¥å†æ—¶é—´**ï¼š2-3 å‘¨ï¼ˆåŒ…æ‹¬æ•°æ®è§‚å¯Ÿå’Œè°ƒä¼˜ï¼‰

**å…³é”®é‡Œç¨‹ç¢‘**ï¼š

- âœ… M1.1: è®­ç»ƒç¯å¢ƒå°±ç»ªï¼ˆç¬¬ 1 å‘¨ï¼‰
- âœ… M1.2: é¦–ä¸ªæ¨¡å‹è®­ç»ƒå®Œæˆï¼ˆç¬¬ 2 å‘¨ï¼‰
- âœ… M1.3: æ¨ç†æœåŠ¡ä¸Šçº¿ï¼ˆç¬¬ 3 å‘¨ï¼‰
- âœ… M1.4: ç°åº¦æµ‹è¯•å®Œæˆå¹¶å†³ç­–ï¼ˆç¬¬ 3-4 å‘¨ï¼‰

---

## Phase 2: æŒç»­ä¼˜åŒ–ï¼ˆPhase 1 å®Œæˆåï¼Œé•¿æœŸè¿è¡Œï¼‰

**ç›®æ ‡**ï¼šæ¨¡å‹ä¼˜åŒ–å’Œè‡ªåŠ¨åŒ–é‡è®­ç»ƒæœºåˆ¶

âš ï¸ **æ³¨æ„**ï¼šæ•°æ®åŸºç¡€è®¾æ–½å·²åœ¨ Phase 1.0 ä¸­å®Œæˆï¼ˆIssue #P1-0ï¼‰ï¼ŒPhase 2 ä¸“æ³¨äºæ¨¡å‹å’Œæµç¨‹ä¼˜åŒ–ã€‚

### Phase 2.1: æ¨¡å‹ä¼˜åŒ–ï¼ˆæŒç»­ï¼Œ10 å°æ—¶ï¼‰

#### Issue #P2-1: æ¨¡å‹è°ƒå‚ä¼˜åŒ–

**ä¼˜å…ˆçº§**ï¼šP2
**é¢„è®¡å·¥æ—¶**ï¼š10 å°æ—¶
**ä¾èµ–**ï¼š#P1-5

**ä»»åŠ¡æè¿°**ï¼š

- [ ] å°è¯•ä¸åŒè¶…å‚æ•°ç»„åˆ
- [ ] å®éªŒä¸åŒçš„ç‰¹å¾å·¥ç¨‹æ–¹æ³•
- [ ] åˆ†æç‰¹å¾é‡è¦æ€§
- [ ] è®°å½•å®éªŒç»“æœ

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] è‡³å°‘å°è¯• 5 ç»„ä¸åŒå‚æ•°
- [ ] æ‰¾åˆ°æ¯” baseline æ›´å¥½çš„é…ç½®
- [ ] æœ‰è¯¦ç»†çš„å®éªŒè®°å½•

---

### Phase 2.2: è‡ªåŠ¨åŒ–ï¼ˆé•¿æœŸï¼Œ10 å°æ—¶ï¼‰

#### Issue #P2-2: è®¾ç½®æ¯å‘¨è‡ªåŠ¨é‡è®­ç»ƒ

**ä¼˜å…ˆçº§**ï¼šP2
**é¢„è®¡å·¥æ—¶**ï¼š6 å°æ—¶
**ä¾èµ–**ï¼š#P1-5

**ä»»åŠ¡æè¿°**ï¼š

- [ ] åˆ›å»º Cloud Functions è§¦å‘è®­ç»ƒ
- [ ] é…ç½® Cloud Schedulerï¼ˆæ¯å‘¨æ—¥å‡Œæ™¨æ‰§è¡Œï¼‰
- [ ] è‡ªåŠ¨éƒ¨ç½²æ–°æ¨¡å‹åˆ° Cloud Run
- [ ] è®¾ç½®é‚®ä»¶é€šçŸ¥

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] æ¯å‘¨è‡ªåŠ¨è®­ç»ƒæˆåŠŸ
- [ ] æ–°æ¨¡å‹è‡ªåŠ¨éƒ¨ç½²
- [ ] æœ‰é‚®ä»¶/Slack é€šçŸ¥

---

#### Issue #P2-3: åˆ›å»ºç›‘æ§ Dashboard

**ä¼˜å…ˆçº§**ï¼šP2
**é¢„è®¡å·¥æ—¶**ï¼š4 å°æ—¶
**ä¾èµ–**ï¼š#P1-0

**ä»»åŠ¡æè¿°**ï¼š

- [ ] åˆ›å»º BigQuery è§†å›¾
- [ ] åœ¨ Looker Studio åˆ›å»º Dashboard
- [ ] æ·»åŠ èƒœç‡ä¸‹é™å‘Šè­¦

**å…³é”®æŒ‡æ ‡**ï¼š

- æ¯æ—¥å¯¹å±€æ•°
- Dire èƒœç‡è¶‹åŠ¿
- æ¨èè‹±é›„åˆ†å¸ƒ
- API å»¶è¿Ÿ P50/P95/P99

**éªŒæ”¶æ ‡å‡†**ï¼š

- [ ] Dashboard å¯è®¿é—®
- [ ] æ•°æ®æ¯æ—¥æ›´æ–°
- [ ] æœ‰å‘Šè­¦æœºåˆ¶

---

## å®æ–½æ—¶é—´çº¿

### æ‰§è¡Œç­–ç•¥

```
å‘¨ | Phase 1                                  | Phase 2
---+------------------------------------------+-------------------------
å‡†å¤‡ | #P1-0 (BigQueryå»ºè¡¨+æ•°æ®å¯¼å…¥, 2-3h)      | -
1  | #P1-1, #P1-2, #P1-3 (ç¯å¢ƒ+æ•°æ®åŠ è½½, 7h)  | -
2  | #P1-4, #P1-5 (è®­ç»ƒ+è¯„ä¼°, 12h)            | -
3  | #P1-6, #P1-7, #P1-8 (æ¨ç†æœåŠ¡, 16h)      | #P2-1 (å¼€å§‹è°ƒå‚)
4  | #P1-9 (ç°åº¦æµ‹è¯•, 4h)                     | #P2-2, #P2-3 (è‡ªåŠ¨åŒ–+ç›‘æ§)
5+ | å…¨é‡ä¸Šçº¿                                  | æŒç»­ä¼˜åŒ–
```

### å…³é”®é‡Œç¨‹ç¢‘

- **å‡†å¤‡é˜¶æ®µ**: å»ºè¡¨å¹¶å¯¼å…¥å†å²æ•°æ®ï¼ˆ2-3 å°æ—¶ï¼‰â† å…³é”®ï¼
- **Week 1**: Python ç¯å¢ƒå°±ç»ªï¼Œå¯ä»¥åŠ è½½æ•°æ®
- **Week 2**: é¦–ä¸ªæ¨¡å‹è®­ç»ƒå®Œæˆ
- **Week 3**: æ¨ç†æœåŠ¡ä¸Šçº¿
- **Week 4**: ç°åº¦æµ‹è¯•å¹¶å†³ç­–
- **Week 5+**: å…¨é‡ä¸Šçº¿ + æŒç»­ç›‘æ§ä¼˜åŒ–

---

## æ€»é¢„è®¡å·¥æ—¶

- **Phase 1ï¼ˆæ ¸å¿ƒï¼‰**: 41-42 å°æ—¶
  - P1-0: 2-3 å°æ—¶ï¼ˆå»ºè¡¨+å¯¼å…¥æ•°æ®ï¼‰
  - P1-1 to P1-9: 39 å°æ—¶
- **Phase 2ï¼ˆä¼˜åŒ–ï¼‰**: 20 å°æ—¶
  - P2-1: 10 å°æ—¶ï¼ˆè°ƒå‚ï¼‰
  - P2-2: 6 å°æ—¶ï¼ˆè‡ªåŠ¨åŒ–ï¼‰
  - P2-3: 4 å°æ—¶ï¼ˆç›‘æ§ï¼‰
- **æ€»è®¡**: 61-62 å°æ—¶

**å®é™…æ—¥å†æ—¶é—´**ï¼šçº¦**3 å‘¨**å®Œæˆ Phase 1 æ ¸å¿ƒåŠŸèƒ½ï¼ŒPhase 2 å¯ä»¥æŒç»­è¿­ä»£ã€‚

---

## é£é™©ä¸ç¼“è§£

| é£é™©               | å½±å“             | ç¼“è§£æªæ–½                                     |
| ------------------ | ---------------- | -------------------------------------------- |
| å†å²æ•°æ®é‡ä¸è¶³     | æ¨¡å‹æ•ˆæœå·®       | ç¡®è®¤è‡³å°‘æœ‰ 50k å¯¹å±€åå†å¼€å§‹è®­ç»ƒ              |
| æ•°æ®å¯¼å…¥å¤±è´¥       | é˜»å¡æ‰€æœ‰åç»­å·¥ä½œ | å…ˆ dry-run éªŒè¯ï¼Œåˆ†æ‰¹å¯¼å…¥                    |
| é¦–æ¬¡è®­ç»ƒæ•ˆæœå·®     | æ–¹æ¡ˆå¯è¡Œæ€§å—è´¨ç–‘ | è®¾å®šåˆç†é¢„æœŸï¼ˆTop-1 > 2%å³å¯ï¼‰ï¼Œå¼ºè°ƒè¿­ä»£ä¼˜åŒ– |
| Cloud Run å†·å¯åŠ¨æ…¢ | ç”¨æˆ·ä½“éªŒå·®       | é…ç½® min_instances=1                         |
| æ¨¡å‹è¿‡æ‹Ÿåˆ         | æ³›åŒ–èƒ½åŠ›å·®       | äº¤å‰éªŒè¯ã€æ­£åˆ™åŒ–                             |

---

## ä¸‹ä¸€æ­¥

### ç«‹å³æ‰§è¡Œï¼ˆIssue #P1-0ï¼‰

1. **ç¡®è®¤ GA4 Property ID**

   ```bash
   # åœ¨BigQueryæ§åˆ¶å°æŸ¥æ‰¾analytics_å¼€å¤´çš„æ•°æ®é›†
   # æ ¼å¼ï¼šanalytics_<property_id>
   ```

2. **åˆ›å»º BigQuery ä¸“æœ‰è¡¨**

   - å¤åˆ¶ `BIGQUERY_SETUP.md` ä¸­çš„å»ºè¡¨ SQL
   - åœ¨ BigQuery æ§åˆ¶å°æ‰§è¡Œ

3. **å¯¼å…¥å†å²æ•°æ®**

   - é€‰æ‹©æ–¹å¼ Aï¼ˆSQL ç›´æ¥å¯¼å…¥ï¼‰æˆ–æ–¹å¼ Bï¼ˆPython è„šæœ¬ï¼‰
   - å…ˆ dry-run éªŒè¯æ•°æ®é‡
   - ç¡®è®¤ â‰¥ 50,000 åœºå¯¹å±€

4. **é…ç½®æŒç»­å†™å…¥**
   - å®ç°`BigQueryService`
   - é›†æˆåˆ°`analytics.service.ts`
   - è®¾ç½®`ENABLE_BIGQUERY_EXPORT=true`å¹¶éƒ¨ç½²

**é¢„è®¡æ—¶é—´**ï¼š2-3 å°æ—¶ï¼ˆå®Œæˆåå¯ä»¥å¼€å§‹è®­ç»ƒï¼ï¼‰

### åç»­æ­¥éª¤

- Issue #P1-1: åˆ›å»º Python è®­ç»ƒé¡¹ç›®ç»“æ„
- Issue #P1-2: å®ç°æ•°æ®åŠ è½½å™¨
- ...

---

**ç‰ˆæœ¬**: v2.0
**æ›´æ–°æ—¥æœŸ**: 2026-01-14
**çŠ¶æ€**: å·²ç¡®è®¤æ¸¸æˆè§„åˆ™ï¼Œå¯ä»¥å¼€å§‹å®æ–½
